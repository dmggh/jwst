

The Calibration Reference Data System

Perry Greenfield
Todd Miller

Abstract

We describe a software architecture and implementation for using rules to
determine which calibration files are appropriate for use in calibrating a
given observation. This new system replaces what had been previously used for
the Hubble Space Telescope (HST) calibration pipelines, a system called the
Calibration Database System (CDBS), and will be used for the James Webb Space
Telescope (JWST) calibration pipelines, and is currently being used for HST calibration pipelines. . The approach used for this can be
easily generalized for use in similar applications that need a rules-based
system for selecting the appropriate file for a given case; we give some
examples of such generalizations that will likely be used for JWST. The core
functionality of the Calibration Reference Data System is available under an
Open Source license.

Introduction

When running automatic calibration pipelines one important capability needed is
the ability to identify automatically the appropriate calibration files that
should be used when calibrating the data. The kinds of calibration files are
typically numerous, and there may be many that have to be applied to a specific
dataset. Examples are dark current, bias, flat field, photometric, and
geometric distortions, among many others. Typically calibration files depend on
particular observing modes or parameters, or may be time variable.
Calibration files also differ across instruments both in purpose and specific 
instantiations of a particular reference type.

Prior Solution

The system that was used for the Hubble Space Telescope (HST) was called the
Calibration Database System (CDBS). It was used successfully for many
years. The experience with it revealed that there were some limitations that
proved to constrain its capabilities, and as a result, a newer system that
removed these constraints was sought. We will briefly describe the design of
CDBS at a high level and the constraints that it posed. This provides the
necessary background for discussing the design goals of CRDS.

The basic design of CDBS was centered around a database that contained
information on each reference file (the generic STScI term for files used to
calibrate data whether they be flat fields, darks, or file containing
appropriate parameters to use in calibration). Typically the database contained
information about the relevant observational parameters (mostly instrument mode
settings and date of applicability). At the highest level, the basic approach
was to run a program for each new dataset being processed (or reprocessed as
the case may be) that essentially performed a query on the database for each
type of reference file needed. The result of the query was a specific reference
filename that would then be set as the value of a particular keyword in the
dataset's header for use by the calibration pipeline.

The calibration pipelines retrieved the names of the appropriate reference
files from the data set's header, and used those to open that reference file
for use in calibration. The reference files were kept in a standard location in
the pipeline processing system. The program that updated the headers with the
selected references files was called "bestref."

In reality, there was much more to CDBS than what has been briefly
described. The system handled the addition of new reference files, first by
validating the files met certain requirements, and then the archiving of those
submitted files. The process for submitting new files involved a good number of
manual steps and checks. One goal of the replacement system was to streamline
the submission process somewhat.

The most critical aspect of the validation requirements for reference files
concerned the keyword values used to match datasets to the appropriate
references.  Unlike dataset parameter keywords which describe a specific
instrument configuration for one observation, reference file keywords
circumscribe range of parameter values for which the reference applies.  In
CDBS, ranges of parameter values were often represented by intermediate values
which expand into the discrete values used to define specific instrument
configurations.  As part of submitting reference files, the intermediate values
were combinatorially exploded into database rows which represented each
possible application of a reference to some discrete instrument parameter
configuration.  As an example, a dataset APERTURE keyword would describe the
specific aperture an instrument was configured to use for one observation. In
contrast, the same APERTURE keyword specified in a reference file would
describe, indirectly, the combined set of different specific APERTUREs that
reference file was capable of supporting.  When multiple parameters were used
to match datasets to references, the number of distinct rows in the CDBS
database was equal to the product of the number of specific values supported by
a particular reference for each parameter.

Furthermore, there were occasions for which standard SQL queries were
insufficient for achieving the desired selection results. In such cases,
software was run to generate custom queries to get around such limitations.

CDBS was used for 24 years of HST's operation. During that period, upgrades and
enhancements were made to how it worked, but for the most part, the design did
not change in any major way.

Limitations in CDBS

Twenty four years provides a long time to learn about what could be
improved. This section highlights what issues proved the most problematic in
using CDBS.

1). Difficulty testing new reference files. The use of a database essentially
limited the system to one set of rules for selecting reference files. Once a
reference file was delivered to the system, effectively the rules for selection
were modified in the operation system immediately. There were occasions when
reference files were deemed to have passed functional testing (i.e., they
performed the correct calibration for the designated cases), but were submitted
with incorrect information about which modes or dates that they should be used
for. As a result, the operational pipeline would only discover that there was a
problem when processing real data, thus resulting in dealing with correcting
mis-processed data (or in some cases, failure to even process). Problems in the
operational pipeline are significant disruptions. In the last few years, a test
version of the database was created so that tests could be performed, but that
introduces synchronization and management issues to make sure what is being
tested corresponds to the previous operational version. Furthermore, if
multiple deliveries are in progress from different instruments, it introduces a
coordination issue to make sure they are either all completed together or in
sequence, which can prove constraining to the needs of each instrument as far
as testing goes.

2) Difficulty in undoing mistakes. A delivery of a file with mistaken
parameters could be difficult to undo. No reference file could be removed from
the database for various reasons. In a number of cases, particularly if the
date that it was targeted for was incorrect, it could seriously corrupt the
selection logic. To take the most common error case: Files often had a
"useafter" date associated with them that indicated that it should be used for
a date after the specified one *if no other file had a later date that was
still before the date of the observation*. If one submitted a file intended to
be used for data after 2000-01-01 but mistakenly provided
1999-01-01 then two new file submissions are required to correct the problem.
One to resubmit the new file with the correct date; the second to resubmit the file
intended to be used after 1999-01-01 so that its useafter date is one second after
the mistaken submission. 

There are other cases where one mistaken submission may require a series of
resubmissions of already submitted files to correct for the effect of the wrong
submission. One such example is if one mistakenly supplies a "wildcard" for a
parameter that should only apply to one case. In this event, all the other
reference files intended for each of the other possible parameter values must
be resubmitted. This makes the potential effects of mistakes serious and thus
requires extreme care in submission.

3) Difficulty in supporting remote usage by astronomers. 
Using the bestref facility remotely
requires providing a web service so that remote processing can get the most up
to date recommendations on the best reference file to use. There is one serious
drawback in this though. Frequently the versions of the calibration software in
the operations pipeline have not yet been publicly released, and there are
times when the latest reference files require the latest software. Such a web
service has the potential of recommending reference files that either are
inappropriate for previous versions of the calibration pipeline software, or
simply will not work with previous versions. As a result, this service was not
provided.

4) Difficulty in allowing customized variants of selection rules. Sometimes
observers or teams have specialized calibration files that they wish to
substitute in place of the standard ones. There was no simple way of allowing a
team to run a customized version of CDBS to support this. The entrenched
software requirements were too numerous (when one develops a system to run in
only one environment, dependencies on that environment easily become entrenched
in the system). Even if no customization was desired, it makes running the
calibration pipeline remotely at another institution very difficult since there
is no simple way to get the the most recent recommendations.

5) Difficulty in providing remote pipelines a consistent bestref
environment. There are times observers *do not* want changing references files
if they wish comparison to previously computed results. They want the same
rules applied, even if they aren't the very best version.
As a "single state" database expressing only the current best reference
assignment rules, reproducing historical results in CDBS was difficult or
impossible.

6) Difficulty in understanding what the effective rules are. The exact
selection rules are embodied in a database with a history of transactions for
which many supersede previous ones. One really only knows the net effect by
running queries on the database for specific cases, even when something quite
simple could summarize what is desired for the current situation. The net
effect of this is that people do not really understand what the rules are, and
that they are not what was intended. Finding mistakes in this situation can be
quite difficult. And once found, can be difficult to rectify.

7) Difficulty in adding new kinds of selection rules. The database schema
effectively constrains what kinds of rules can be used. More complex rules
either lead to horrendously complex queries, or custom software to generate
custom queries. The use of the custom software/queries ends up making the system
even more opaque.

The Crux of a Different Approach

It became apparent that many of the limitations ultimately came down to the
dependence on a database as the repository for the selection rules. This has a
number of drawbacks in this particular application:

1) Databases are effectively one state systems. Yes, one can deal with multiple
states but usually at great complexity.
2) Databases do not make it simple to distribute software since installing,
administering and maintaining a database elsewhere is a major task, and keeping
them synchronized to the master copy is yet a greater complexity
3) Once established, changing the structure of database is difficult,
particularly with a systems used in operations.

Is it in fact necessary to use a database to hold the rules? In reviewing all
the previous and anticipated cases for HST and JWST, it did not appear that a
database was necessary for selection rules, and that a simpler and more
flexible approach could be chosen. Indeed, all that appears to be needed is to
encompass a version of the rules in a simple text file. In doing so there are a
number of immediate benefits:

1) the rules are explicit
2) multiple versions of these rules may exist without conflict, and used in
different contexts simultaneously without confusion.
3) these rule files may be easily distributed so that remote users can run the
"bestref" functionality remotely without needing to install or administer
complex software.
4) the rules are easily customized, even by hand if necessary if users wish to.

High level organization of CRDS

The software for CRDS can be considered to be in one of three categories:

1) supporting the bestref functionality

2) supporting submitting new reference files and all the issues that go with
that

3) Supporting format, semantic, and parameter constraint checking for both
references and rules files.  Capability to detect typos, duplicate lines, and
grammatical errors in rules files.   Capability to analyze basic properties
such duplicate or deleted rows,  by pseudo-mode, for supported tables files.

4) providing utilities for making CRDS useful in operations, for instrument
scientists that must generate and monitor reference files, and end users.

Each of these will be described in a separate section. Since most of the design
is centered around the first category, most of the description will be centered
around that.

Bestref Functionality

Design

The system is centered around rules files that describe (for one version) 
how reference files should be selected for a single type of
reference file. In a general sense, the file consists of a header of sorts that
describes information about what kind of reference file that it is applied to,
what the relevant information from the data set is needed to make that
selection, and other bookkeeping information. Following that header are the
rules. Generally these are nested sets of criteria that are used to
successively narrow down the selection until a single result is determined. It
is important to understand that there is no intrinsic limit to what structures
can be supported. If more complex cases arise, new structures can be added to
the library to support these. The following lists existing and possible kinds
of selections structures. Those that already are supported are marked with an
'*'. The ones that are not supported are intended to illustrate possible
extensions that are not purely hypothetical. The following examples of files
will illustrate specifically these structures.

a) matching on sets of discrete parameter values. That is, the item associated
with this specific set of parameters is selected if the parameter values are
matched according to one of several matching approaches. An item may be a file
name, or a nested set of rules that will be evaluated in turn.  
There are a number of different parameter match types, literal, or-glob,
pure regex, between, not, relational, etc.  In the case of multiple parameters,
each parameter is matched across all match cases using a process of elimination
(winnowing) which successively narrows the possible match cases.

b) matching on a sequence of dates. This corresponds to the useafter mechanism
in CDBS. Normally these items will be sorted in date/time order, and the
date/time of the observation is used to select the appropriate item in the list
using a binary search.

c) matching software version requirements. This structure indicates selection
based on versions of the software which item should be selected. It may use
specific versions, or relative (e.g., any version before or up to the specified
version, or any version after the specified version).

d) getting bracketing files. This is useful if some sort of interpolation
between reference files is desired, in which case a pair of results is
returned.

e) matching on ranges of non-discrete values. For example, this may select a
file if an observational parameter is in the specified range. Normally, this
would be a one-dimensional selection, though even more complex multidimensional
volumes could be constructed if need be.

xxx example 1 (highlighting a & b)

selector = Match({
    ('MIRIFULONG', 'FAST', 'FULL') : UseAfter({
        '2015-01-27 12:05:34' 'jwst_miri_dark_0029.fits',
        '2015-03-22 00:29:01' 'jwst_miri_dark_0032.fits',
        '2015-04-07 09:14:00' 'jwst_miri_dark_0047.fits',
        ...
        }),
    ('MIRIFUSHORT', 'SLOW', 'FULL') : UseAfter({
        '2015-01-25 12:06:34' 'jwst_miri_dark_0099.fits',
        '2015-03-21 00:28:01' 'jwst_miri_dark_0101.fits',
        '2015-04-08 09:13:00' 'jwst_miri_dark_0127.fits',
        ...
        }),
        ...
})

xxx example 2 adding c

selector = SelectVersion({
   '<3.1':    'jwst_miri_flat_0065.fits',
   '<5':      'jwst_miri_flat_0073.fits',
   'default': 'jwst_miri_flat_123.fits',
})

xxx example 3 illustrating d

selector = Bracket({
    1.2: "cref_flatfield_120.fits",
    1.5: "cref_flatfield_124.fits",
    5.0: "cref_flatfield_137.fits",
})

Here, a parameter value of 1.3 returns the value:

('cref_flatfield_120.fits', 'cref_flatfield_124.fits')

xxxx example 4 illustrating e

selector = Match({
    ('WFC', 'N/A', 'BETWEEN 1220 1530', 'FR782N') :  "hst_wfc3_flatfile_0027.fits",
    ('WFC', 'N/A', 'BETWEEN 1530 1690', 'FR782N') :  "hst_wfc3_flatfile_0028.fits",
    ...
})

Here a wavelength of 1300 (between 1220 and 1530) results in the partial match
of 'hst_wfc3_flatfile_0027.fits' and eliminates "hst_wfc3_flatfile_0028.fits"
as a candidate.   Since BETWEEN can be used in an arbitrary Match parameter
slot,  potentially multiple times,  volumes can be described, and also
described in concert with other types of match syntax for other parameters
such as wildcard matching or regular expressions.

XXXXXXX I think the capabilities of (e) are actually folded into Match()
described in (a),  where each individual parameter of a match case can use
one of several match syntaxes.   Further,  there is no requirement that the
match expressions of the same parameter use the same method across all cases,
and indeed it is common to use N/A which is a specialized kind of match.

XXXX I documented all this stuff here:

XXXX   https://jwst-crds.stsci.edu/static/users_guide/rmap_syntax.html#selectors

XXXX By far the most common match syntax used is the literal-value-or-glob,
including the degenerate case of a single literal value.  Unlike CDBS which had
discrete rows for every combination of discrete parameter values, CRDS
summarizes the combinatorial explosion of parameter possibilities into a single
concise multi-parameter expression by virtue of the matching syntax.  It is far
more comprehensible to look at one multi-parameter match expression with
or-globs than it is to scan 60 or 100 simple rows in the CDBS database.
Another common match expression is N/A.  BETWEEN has also been used.

The system is based on these files (which we refer to rmap files since they
indicate the mapping to reference files) but also involves a hierarchy of
related files that are called context files, which provide a nested 
organizational structure corresponding to the functions at different levels. Essentially context files are
text files that define a set of related files that are to be used for
that configuration.
Instrument context files collect all the rmap files for that
instrument. This file effectively defines the versions of all the rmap files
for each reference file types that comprise the version of recommendations in
effect for that instrument. In the example of the instrument context file
below, one can see that each distinct rmap file has a unique name. If anything
is changed in an rmap file, it gets a new name

xxx example of instrument context file

Likewise, there is a pipeline context file that lists the instrument context
files that define the versions in effect for the pipeline being run. As with
rmap files, instrument context files all have unique names. Any change of
content results in a new name for an instrument context file. Finally, the same
is true for pipeline context files. The net result is that a pipeline context
file deterministically identifies all the rules in use for a pipeline. 

Note that one can run any number of pipeline environments, and each may use a
completely different pipeline context if need be, each of which will have some
sort of different rules for how reference files are selected.

xxx example of pipeline context file

This hierarchy is designed to match that for JWST and as such is currently
designed around the current levels of hierarchy. It is a possible generalization
that would allow it to deal with arbitrary levels of heirarchy, perhaps
different in number depending on the branch taken. Achieving that would
take significant modifications but is possible. 

Practicality and Restrictions of this design

This approach assumes that the number of matching rules is reasonable for a
text file (e.g., fewer than 10,000 lines or so). It also assumes that the
number of versions of such files is reasonably bound (again, not more than a
few thousand). The most likely driver for the number of rules files versions is
the addition or modification of new reference files as a function of time. This has
been the case for HST, where it is not uncommon to generate new dark files for
every day. For a mission that may last a decade or more we are looking at
approximately 3-4 thousand if updated daily. In fact, HST updates the
configuration more infrequently (e.g., once a week even if there is a reference
file for each day).

In cases where updates are much more frequent, and the system that uses
them must be reconfigured after each update, CRDS may not be practical. This
may be the case where new calibration files are obtained every few minutes and
automatically turned into reference files for immediate use by a calibration
pipeline.

Language independence

This implementation has been done completely in Python. Although the rmap files
have a Python flavor to them (arguably it is more of a JSON flavor), nothing
requires this functionality to be performed in Python. To date Python has
proven fast enough to generate the bestref functionality, even for recomputing it
for large numbers of exposures, as is needed to determine which data sets must
be reprocessed as a result of changes to the configuration.

Adding and updating reference files, rmaps and contexts

While the design of the system is very much centered around how reference file
recommendations are made, that is hardly the only important aspect of the
system. How does one submit new files and ensure the integrity of the system as
the content evolves?

One of the important goals for CRDS was to streamline the process of submitting
new files while ensuring that files are well checked before committed, at least
for common use cases for new Reference files. A completely manual approach is
outlined here before addressing more automatic schemes. For the time being, the
details of how files are actually submitted is deferred to the next section

Supposing one or more new references files of a specific type for a specific
instrument are ready to be tested and used in the operations system/:

1) submit each of the reference files (with validation of each file being part
of the submission process). This is expected to generate unique names for each
of the submitted reference files
2) edit the rmap for that reference file type to include the necessary changes
to use these (most likely either a replacement of older versions or the
addition of time-variable ones).
3) submit the updated rmap file (again with implied validation for correctness)
and again, generating a new, unique rmap file name that represents the version
of the file in the system that has the desired changes.
4) edit the instrument context file to use the new version of the rmap file.
5) submit the updated instrument context file (with validation and generating a
new, unique name)
6) edit the pipeline context file to use the new version of the instrument
context file.
7) submit the updated pipeline context file (with validation and generating a
new, unique name)

At this point the new reference files can be used in an operational
context. Normally, it is expected that they will be tested on a test version of
the operations system by at least running the standard regression test suite
using the new configuration, perhaps with specific tests for the purpose of
testing the new reference files in use. These tests can be performed simply by
specifying a different pipeline context than the one currently being used in
operations, and without impacting the operations behavior.

When tests have been suitably passed, then the operations system can be updated
to use the new context. Should tests indicate that the new context has
problems, it can simply be ignored and never used. Presumably corrections will
be made to the reference files and the corresponding rules to generate a new,
correct context. However, if changes are made to the CRDS software itself,
something that happens frequently in its early stage of development and use,
it does require a separate test system to test updates to CRDS. Currently, 
deliveries always use the test environment, though it is expected that when
software updates are infrequent, the above model will be used for pure
reference file deliveries.

Since any number of context can exist, one can have several in testing
simultaneously. If that is the case, one still needs to be careful in
determining if different contexts need merging of information (as could happen
if different instruments are submitting new files independently).

For JWST, most instances of merging will be as simple as generating a
pipeline context that uses the appropriate instrument context (the items
most likely to be different; i.e., it is not expected that an instrument 
will be merging items at a lower level in the hierarchy).

In any case, if the operations system does end up using an incorrect pipeline
context, reversion to a previously good one is quite simple (something that
could be quite tricky in CDBS).

In the context of HST (see section xxx), reversion to prior sets of 
rules has been used to
support pipeline regression testing and coordinate CRDS with available
historical system states of the rest of the pipeline.

Streamlined updates

While this multi-step update process may be necessary in more complex cases, the
great majority of reference file submissions fall into one of two categories:
1) the replacement of existing references files (e.g., a better flat field) or
the addition of a reference file for a previously unsupported mode; or 2) the
addition of time-dependent references files to address data for specific time
ranges.

In either of these cases, it is quite useful to streamline the process to
effectively make it one step. Namely by the fact of submitting the reference
files, automatically updating and submitting the appropriate rmap to use it,
and in turn, making the corresponding updates and submissions to the context
files. As a result of these submissions, the user then is given all the
relevant names for the new reference files, rmap, and context files, most
importantly the pipeline context file. For this to work properly, the user must
indicate which pipeline context they are basing the changes on. Normally this
is the last one,  known as the "edit context" which can be modified several
times in advance of adopting the context as operational in the pipeline.  

There are several other options as well: 

- operational
- one of last 10
- user specified.  

Usually only the "edit context" is used, but the other choices
enable branching from a common ancestor.  Other activities which are
streamlined here are automatic file checking of reference and generated rules
files, collection of file metadata, and automatic version-to-version
differencing of the generated rules for inspection by the submitter and
verification that the intended changes have occurred prior to confirming
the submission.  Finally, it includes delivery of the files to the archive.

Reference File submission details

The machinery for submitting reference files is an interactive web-based
system. The ability to submit files or make changes requires user
validation. Figure xxx shows a screen shot of the home page of the CRDS
system, which is visible to the public. The submission capabilities 
are indicated in the xxx links in
xxx. Figure xxx shows the submission web page for updates for reference
files. This examples is for xxx.


File submission is limited to authenticated users. The fully automatic
standard process is dubbed "Batch Reference
Submission" in reference to submission of a pile of files for one instrument,
multiple types,  and automatic certification and rules updates.

The user identifies the local files designated as the files to replace existing
ones. When all the updates have been identified, the submit button [or
whatever] is clicked, and CRDS will then validate each of the reference
files. If they all pass validation, the user will be presented the results of
the results that will be produced (e.g., the new filenames for the reference
files, rmaps and context files, and other summary information). An example of a
successful validation is shown in Figure xxx. At this point the user confirms
the submission after which they will be assigned unique names, added to the
CRDS database of reference files, sent to the STScI archive for archiving, and
placed in the disk-based repository of reference files. If the validation
doesn't pass, the results indicate what the problem is so the user may make the
necessary corrections. Figure xxx shows such a summary of problems.

The subsequent updates to rmap and context files also are validated, primarily
to ensure the syntax is correct.

Reference File Validation

This is handled by using the tools that the JWST pipeline use to validate the
reference files. These are based on data models that use JSON Schema (ref xxx)
to define the mandatory aspects of the data expected, including all the
expected data elements (whether arrays or tables), the allowable dimensionality
and datatype, and required metadata.

The required metadata includes information on who made the reference file, how
the reference file was made and related information (CRDS will also add
standard metadata related to the submission aspects, such as when the file was
submitted.)

There are further checks on file submissions that are intended to warn regarding
suspicious changes. These changes may be valid, but like indicate a mistake. The
following such situations raise a warning on submission:

1) The reversion of a file to a previous version. For example, if a rmap has an
existing reference file name replaced by one that is earlier in the submission
sequence, that would be unusual, and the submitter warned about this reversion.
Likewise if instrument or pipeline contexts point to earlier rmaps or instrument
contexts, respectively, that raises a warning.

2) If someone tries to commit files that were based on a pipeline context that
is no longer the latest, a warning will be raised. By doing so they may reverse
changes made by other instruments that have gotten into contexts after they
started making edits (this normally would not happen with streamlined submission
processes, but only when users are making submissions for individual components
thus raising the possibility they are bypassing subsequent changes).

3) other cases? xxx

Utilities

Utilities are generally targeted to one or more of three classes of users:
Operations, Instrument Scientists (i.e., those that must create and maintain
reference files), and general users. Some utilities are useful for only one of
these classes of users whereas others may be more broadly useful. We will
organize this section by this class of users. Where a utility has other uses we
will indicate that.

Operations

Affected files utility: Given a list of datasets, determine which ones have
been affected by a change in a pipeline context. Normally it is expected that
the relevant selection parameters for each data set is contained in a database
to avoid having to examine the contents of each dataset. This utility needs to
run in a reasonable amount of time since it may have to do this comparison for
hundreds of thousands of datasets. The inputs to the utility is a text list of
data sets, and the two pipeline contexts being compared. The results of this
can be used to determine which data sets must be reprocessed to take advantage
of any improved reference files.

Active reference files in a context: List all reference files used in a
pipeline context. This indicates what files may be needed to process the
data. (possibly useful for other classes of users)

% python -m crds.list --contexts jwst_0059.pmap --references
jwst_fgs_gain_0000.fits
jwst_fgs_gain_0001.fits
jwst_fgs_ipc_0001.fits
jwst_fgs_ipc_0002.fits
jwst_fgs_linearity_0004.fits
jwst_fgs_linearity_0005.fits
jwst_fgs_mask_0002.fits
jwst_fgs_mask_0003.fits
jwst_fgs_readnoise_0000.fits
jwst_fgs_readnoise_0001.fits
...

Inverse mapping: Which rmaps and contexts use a specific reference file (e.g.,
if one finds that one was defective, identify all the pipeline contexts that
used that file so that users may be notified)?

% python -m crds.uses jwst_fgs_gain_0000.fits
...
jwst_0078.pmap
jwst_0079.pmap
jwst_0080.pmap
...
jwst_fgs_0003.imap
jwst_fgs_0004.imap
jwst_fgs_0005.imap
...
jwst_fgs_gain_0000.rmap
jwst_fgs_gain_0001.rmap

Instrument Scientists

Difference in rules between two contexts: Summarize what has changed in the
rules between two pipeline or instrument contexts. This allows instrument
scientists to quickly identify the changes made.

% python -m crds.diff jwst_0080.pmap jwst_0081.pmap --brief --squash-tuples
jwst_miri_regions_0004.rmap jwst_miri_regions_0005.rmap -- MIRIFUSHORT 12 SHORT N/A -- added Match rule for jwst_miri_regions_0006.fits
jwst_miri_0048.imap jwst_miri_0049.imap -- regions -- replaced jwst_miri_regions_0004.rmap with jwst_miri_regions_0005.rmap
jwst_0080.pmap jwst_0081.pmap -- miri -- replaced jwst_miri_0048.imap with jwst_miri_0049.imap

General users

Compare retrieved data with current pipeline context: A user has downloaded
data and wishes to see what data may need to be re-retrieved since the
reference files it used are not the currently recommended ones. A variant on
this is to update the headers of the files with the newly recommended files
(though for the JWST pipelines, this isn't normally necessary). This typically
will be run remotely and thus need network access to the CRDS server.

Technical implementation details

All the software (aside from a limited amount of web interface tools) is
written in Python. The bestref functionality uses the following Python
libraries (i.e., what isn't part of the Python Standard Library
distribution). It was originally written to use Python 2, but has since been
updated to use Python 3. The server-side libraries have not been ported to 
Python 3 yet.

Client side dependencies:

- rules file checking uses the **Parsley** parser generator package to define a grammar capable of detecting duplicate lines (cut-and-paste errors)

- reference and dataset file header access use:

  - jwst_lib.models, jwst_lib.stpipe, jwst_lib.modeling (STScI)
  - PyYaml
  - pyasdf (STScI)
  - astropy
  - numpy


Server-side dependencies:

The web-based functionality uses the Django framework and the MySQL database
backend. The additional following libraries are used.

- Apache web server using the Python mod_wsgi as the library interface.
- django-file-upoad (source code subsumed into CRDS code with modifications):
  Used to  manage parallel file uploads, drag-and-drop, progress bars, data rate info,  remote file deletion,  pause/resume,  etc.)
- django-locking (source code subsumed into CRDS code with modifications):
  This is database-backed resource locking used to provide "instrument locks" to limit submissions to one person per instrument (to prevent concurrent submissions).
- django-json-rpc: Supports the interface between the server and clients.
- django-dbbackup: Used to backup the database and mirror the database between
  different environments
- pytz: timezone support
- jQuery/jQuery-UI: web page interface support
- DataTables: Table display and manipulation for jQuery
- MochiKit: Javascript debug shell used by django-json-rpc.
- memcached / libevent / python-memcached: supports cached results on server

Web uploads are capably (not perfectly) handled by the django-file-upload
system which is fully integrated with the CRDS code base.  An end-to-end
checksum (sha1sum-based) verification of file uploads would be desirable
for extremely large
(DVD-sized) files.  Direct copies to the CRDS server file upload directories
can be used to bypass inefficient (and potentially less reliable) remote
web-based file uploads.

A significant design issue exists with processing and ingesting unbounded
amounts of data in a single file submission and web transaction.  
The primary limitation of large numbers of files and/or high volumes
of data is the time required to copy and compute 
the sha1sum for the file within
the web server.  Each 4G JWST file currently takes on the order of 
2 minutes just to copy or checksum.   This basic data transfer
time dwarfs the timing one would ideally desire for a web response,  
tens of milliseconds, putting CRDS deep into the regime of "long polling".    
Because of the current implementation, the web response time is
unbounded and at risk of exceeding proxy timeouts which cancel 
the overall transaction with the web server.   Processing times for 
real world HST file submissions have approached an hour and
in practice have exceeded generous proxy timeout limits.

This can be
mitigated by partitioning files into multiple smaller submissions (also smaller
incremental *failure groups* for certification errors or other problems) or
using alternate backend delivery mechanisms for particularly large submissions.
After initial bootstrappng, all incremental JWST reference updates to date have
been successfully ingested using the web interface.  Fully addressing large
file submissions requires the addition of background processing which isolates
file ingest processing from web protocol timing; this amounts to the addition
of a miniature hidden pipeline in CRDS.  

An additional challenge associated
with the submission of large volumes of data is the loss of processing time
associated with a single errant file forcing the cancellation of the entire
batch.  As the number of files and volume of data in one batch increases, the
processing time increases linearly, and the penalty for errors in submitted
files also increases linearly.  It's bad when file 1199 of 1200 fails wiping
out an entire day of ingest processing.  

Automatically partitioning submissions into reasonable chunks of work is a 
challenging requirement. Because of the unknown semantics and 
interrelationships between the potentially multiple (new or old) types 
in a single submission, human intelligence is required to partition files 
into meaningful groups which can be isolated and used independently 
of other potentially failing groups. However, it is relatively
easy for submission system to warn the user regarding excessively large 
submission requests with suggestions that the submission be partitioned.

Reference files in FITS, JSON, and ASDF format are supported.

Enabling pipeline flexibility

CRDS was designed to allow running the JWST calibration pipelines remotely much
more easily. HST users could always rerun pipelines at their home institutions,
but it was considerably more painful to do since they had to determine what
reference files their data sets required and retrieve them from the archive
before they could run the pipeline. Even the first task was made more
complicated by the fact that there was no reliable way to find the current best
reference files.

For JWST, CRDS will provide a web service that can be accessed
remotely. Furthermore, the JWST calibration pipelines have been designed to
make the request directly to CRDS to determine which reference files to use and
download the file if it is not available locally. This means anyone can run the
pipeline remotely and be assured that the right reference files will be used,
and retrieved if necessary.

In fact, the bestref functionality has been designed to work entirely locally
if all the necessary context and rmap files are available locally. And the
normal mode of operation is to cache all the files for that functionality even
if running remotely. Once these files are downloaded, the only necessary
internet connection is to check if the context used locally is the current one
being used for JWST operational pipelines. Otherwise, it is entirely possible
to run this functionality entirely locally. The bestref functionality is very
portable and easy to distribute with with the calibration pipeline software.

Another aspect of the pipeline flexibility is that this also allows users to
control the reference file rules. For example, there are cases for which users
prefer to continue using the same reference files as for previous data that has
been calibrated remotely in preference to using slightly better reference
files, but introducing an inconsistency in processing the different data
sets. Users may be able to specify a specific pipeline context instead of the
current context.

Finally, users may edit the rules files directly to replace STScI supplied
reference files with their own ones, or even to add a custom step to the
pipeline with an entirely new set of rules and reference files.

Use for HST

Although CRDS was designed for use with JWST, it was desired to upgrade the HST
system to use it as well. The advantage for JWST is that CRDS would be heavily
tested in an operational environment. The bestref machinery is essentially
identical, but different in application since HST pipelines populate the data
set's header with the reference files to be used rather than the calibration
pipeline using the service.

The major challenge for HST was in translating the effective rules that existed
in the database into rmap files and ensuring that CRDS was producing the same
results. This was done by doing the recommended comparison for every data set
in the HST archive. The generation of the rmaps was automated since the target
was constantly changing for HST because of continual reference file
updates. The cycle of generating rmaps and making the reference file comparison
for all datasets was repeated many times until CRDS went operational. This was
further complicate by the fact that the database that contained the CDBS best
references was not reliable. The differences that arose had to be further
tested with the operations bestref facility (which requires using actual
datasets thus is much slower).

This testing uncovered a number of yet undiscovered problems with the CDBS
recommendations, which were then fixed in both.

The two systems were run in parallel for many months with the results being
compared, first with CDBS used for the actual results, then switching to CRDS
as the primary system. CDBS has since been disabled.

Other Applications

It is important to realize that this system has a wider range of application
than just for selecting appropriate reference files. It can act as a selector
many uses so long as the number of selections is not enormous, and the set of
selection parameter is reasonably consistent and bounded for all data
sets. Other uses are already envisioned for JWST. For example, it will be used
to determine which calibration pipeline to run for the dataset supplied. 
So rather than supplying a reference file to use, it will supply the pipeline 
to execute (either as a name of an executable, or more exactly, a pipeline 
configuration file that the pipeline startup system uses to execute the right
pipeline). It may also be
used to aid in mapping data files to the appropriate data analysis object model
for the data analysis software.

In cases where the parameter sets branch significantly (e.g., when dealing with
data from widely different instruments or even observatories where it is likely
very different conventions are being used for metadata) one may possibly invoke
CRDS tools iteratively, using the first iteration to branch to different sets of
rules on a small subset of the metadata, to cases where each branch has more
consistent metadata.

Licensing and Availability

The bestref client library has a 3-clause BSD and available through its
repository (xxx). The server side software (e.g., the machinery that handles
file submissions and web services) is not publicly available due to security
concerns, though it is possible that it may be made publicly available once it
has been vetted to be free of any security issues. We will make it available to
qualified institutions and individuals provided that they agree not to make it
publicly available. The client library is quite portable. The server-side
software has more local (STScI) dependencies as well as library dependencies,
and all the configuration, administration , and security issues providing a
server entails.

Acknowledgments

This work was funded by both HST and JWST xxx. The implementation was aided by
Jonathan Eisenhamer, and the integration into the operations system by Michael
Swam. Testing from the instrument scientist perspective was carried out by Rosa
Diaz and Matthew McMaster. Motivations for the work were provided by the weekly
Science Software Branch Donut meeting.

References

Swam, M., Lubow S., Hurt, L., "The HST BestRef System--Determining the proper
calibration reference files for an HST exposure", 2004, ASP Conference Series,
314, 824.

Cox, C., Tullos, C., "The calibration data base for the Hubble Space Telescope",
1993, SPIE, 1945, 69.

Cox, C., Lubow, S., Tullos, C., "New design for the Hubble Space Telescope
calibration database", 1998, SPIE, 3349, 218.

Lubow, S., "New Calibration Systems Projects at STScI", 1997, 1997 HST
Calibration Workshop, Casertans, et al, eds., 513

Lubow, S., Cox, C., Hurt, L., Simon, B., "Redesign of CDBS", STScI internal
document, 1997. http://www.stsci.edu/hst/observatory/crds/documents/redesign.pdf



